True
11721506816
0
SqueezeNet(
  (features): Sequential(
    (0): Conv2d(3, 96, kernel_size=(7, 7), stride=(2, 2))
    (1): ReLU(inplace=True)
    (2): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=True)
    (3): Fire(
      (squeeze): Conv2d(96, 16, kernel_size=(1, 1), stride=(1, 1))
      (squeeze_activation): ReLU(inplace=True)
      (expand1x1): Conv2d(16, 64, kernel_size=(1, 1), stride=(1, 1), groups=16)
      (expand1x1_activation): ReLU(inplace=True)
      (expand3x3): Conv2d(16, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=16)
      (expand3x3_activation): ReLU(inplace=True)
    )
    (4): Fire(
      (squeeze): Conv2d(128, 16, kernel_size=(1, 1), stride=(1, 1))
      (squeeze_activation): ReLU(inplace=True)
      (expand1x1): Conv2d(16, 64, kernel_size=(1, 1), stride=(1, 1), groups=16)
      (expand1x1_activation): ReLU(inplace=True)
      (expand3x3): Conv2d(16, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=16)
      (expand3x3_activation): ReLU(inplace=True)
    )
    (5): Fire(
      (squeeze): Conv2d(128, 32, kernel_size=(1, 1), stride=(1, 1))
      (squeeze_activation): ReLU(inplace=True)
      (expand1x1): Conv2d(32, 128, kernel_size=(1, 1), stride=(1, 1), groups=32)
      (expand1x1_activation): ReLU(inplace=True)
      (expand3x3): Conv2d(32, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32)
      (expand3x3_activation): ReLU(inplace=True)
    )
    (6): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=True)
    (7): Fire(
      (squeeze): Conv2d(256, 32, kernel_size=(1, 1), stride=(1, 1))
      (squeeze_activation): ReLU(inplace=True)
      (expand1x1): Conv2d(32, 128, kernel_size=(1, 1), stride=(1, 1), groups=32)
      (expand1x1_activation): ReLU(inplace=True)
      (expand3x3): Conv2d(32, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32)
      (expand3x3_activation): ReLU(inplace=True)
    )
    (8): Fire(
      (squeeze): Conv2d(256, 48, kernel_size=(1, 1), stride=(1, 1))
      (squeeze_activation): ReLU(inplace=True)
      (expand1x1): Conv2d(48, 192, kernel_size=(1, 1), stride=(1, 1), groups=48)
      (expand1x1_activation): ReLU(inplace=True)
      (expand3x3): Conv2d(48, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=48)
      (expand3x3_activation): ReLU(inplace=True)
    )
    (9): Fire(
      (squeeze): Conv2d(384, 48, kernel_size=(1, 1), stride=(1, 1))
      (squeeze_activation): ReLU(inplace=True)
      (expand1x1): Conv2d(48, 192, kernel_size=(1, 1), stride=(1, 1), groups=48)
      (expand1x1_activation): ReLU(inplace=True)
      (expand3x3): Conv2d(48, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=48)
      (expand3x3_activation): ReLU(inplace=True)
    )
    (10): Fire(
      (squeeze): Conv2d(384, 64, kernel_size=(1, 1), stride=(1, 1))
      (squeeze_activation): ReLU(inplace=True)
      (expand1x1): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), groups=64)
      (expand1x1_activation): ReLU(inplace=True)
      (expand3x3): Conv2d(64, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=64)
      (expand3x3_activation): ReLU(inplace=True)
    )
    (11): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=True)
    (12): Fire(
      (squeeze): Conv2d(512, 64, kernel_size=(1, 1), stride=(1, 1))
      (squeeze_activation): ReLU(inplace=True)
      (expand1x1): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), groups=64)
      (expand1x1_activation): ReLU(inplace=True)
      (expand3x3): Conv2d(64, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=64)
      (expand3x3_activation): ReLU(inplace=True)
    )
  )
  (classifier): Sequential(
    (0): Dropout(p=0.5, inplace=False)
    (1): Conv2d(512, 15, kernel_size=(1, 1), stride=(1, 1))
    (2): ReLU(inplace=True)
    (3): AdaptiveAvgPool2d(output_size=(1, 1))
  )
)
total_trainable_parameters are : 141519
one of the best validation acc found
epoch:[1/90],memory:[0.26502084732055664/10.91650390625], lr:[0.003]
train_accuracy:0.42565, train_loss:2.0410595637480418
val_acc:0.43230277185501065,val_loss:2.0255053136140297

one of the best validation acc found
epoch:[2/90],memory:[0.2693157196044922/10.91650390625], lr:[0.003]
train_accuracy:0.42565, train_loss:2.0370262799739836
val_acc:0.4324360341151386,val_loss:2.0252793530411304

one of the best validation acc found
epoch:[3/90],memory:[0.2693157196044922/10.91650390625], lr:[0.003]
train_accuracy:0.42565, train_loss:2.036238168414434
val_acc:0.43250266524520253,val_loss:2.023211626864191

one of the best validation acc found
epoch:[4/90],memory:[0.2693157196044922/10.91650390625], lr:[0.003]
train_accuracy:0.42565, train_loss:2.035904705953598
val_acc:0.4326359275053305,val_loss:2.0234939330168116

epoch:[5/90],memory:[0.2693157196044922/10.91650390625], lr:[0.003]
train_accuracy:0.42565, train_loss:2.035495426829656
val_acc:0.4324360341151386,val_loss:2.032054497234857

epoch:[6/90],memory:[0.2693157196044922/10.91650390625], lr:[0.003]
train_accuracy:0.42565, train_loss:2.0357061305999755
val_acc:0.4324360341151386,val_loss:2.0241742211618403

epoch:[7/90],memory:[0.2693157196044922/10.91650390625], lr:[0.003]
train_accuracy:0.42565, train_loss:2.0353090879917146
val_acc:0.43256929637526653,val_loss:2.02408057680008

epoch:[8/90],memory:[0.2693157196044922/10.91650390625], lr:[0.003]
train_accuracy:0.42565, train_loss:2.034978880310059
val_acc:0.4324360341151386,val_loss:2.024438929201952

epoch:[9/90],memory:[0.2693157196044922/10.91650390625], lr:[0.003]
train_accuracy:0.42565, train_loss:2.035138012933731
val_acc:0.43256929637526653,val_loss:2.02303238743658

epoch:[10/90],memory:[0.2693157196044922/10.91650390625], lr:[0.003]
train_accuracy:0.42565, train_loss:2.0348403988838197
val_acc:0.43256929637526653,val_loss:2.024658036638679

epoch:[11/90],memory:[0.2693157196044922/10.91650390625], lr:[0.003]
train_accuracy:0.42565, train_loss:2.034963338200251
val_acc:0.43250266524520253,val_loss:2.023342829650399

epoch:[12/90],memory:[0.2693157196044922/10.91650390625], lr:[0.003]
train_accuracy:0.42565, train_loss:2.0347621685504915
val_acc:0.43236940298507465,val_loss:2.0238309146752997

epoch:[13/90],memory:[0.2693157196044922/10.91650390625], lr:[0.003]
train_accuracy:0.42565, train_loss:2.0347857088247934
val_acc:0.43256929637526653,val_loss:2.024193927931633

epoch:[14/90],memory:[0.2693157196044922/10.91650390625], lr:[0.003]
train_accuracy:0.42565, train_loss:2.034672715028127
val_acc:0.43256929637526653,val_loss:2.0240370088548802

epoch:[15/90],memory:[0.2693157196044922/10.91650390625], lr:[0.003]
train_accuracy:0.42565, train_loss:2.0345997525850934
val_acc:0.4324360341151386,val_loss:2.023459617262964

epoch:[16/90],memory:[0.2693157196044922/10.91650390625], lr:[0.003]
train_accuracy:0.42565, train_loss:2.0346016572475434
val_acc:0.4324360341151386,val_loss:2.023705539672868

epoch:[17/90],memory:[0.2693157196044922/10.91650390625], lr:[0.003]
train_accuracy:0.42565, train_loss:2.034502799050013
val_acc:0.4324360341151386,val_loss:2.0234960789111125

epoch:[18/90],memory:[0.2693157196044922/10.91650390625], lr:[0.003]
train_accuracy:0.42565, train_loss:2.034589681816101
val_acc:0.43230277185501065,val_loss:2.024344002704885

epoch:[19/90],memory:[0.2693157196044922/10.91650390625], lr:[0.003]
train_accuracy:0.42565, train_loss:2.034406405735016
val_acc:0.43250266524520253,val_loss:2.0228559171467193

epoch:[20/90],memory:[0.2693157196044922/10.91650390625], lr:[0.003]
train_accuracy:0.42565, train_loss:2.034372584835688
val_acc:0.43236940298507465,val_loss:2.0266918979728143

epoch:[21/90],memory:[0.2693157196044922/10.91650390625], lr:[0.003]
train_accuracy:0.42565, train_loss:2.0343315834681195
val_acc:0.43256929637526653,val_loss:2.02297395696518

epoch:[22/90],memory:[0.2693157196044922/10.91650390625], lr:[0.003]
train_accuracy:0.42565, train_loss:2.034368395535151
val_acc:0.43236940298507465,val_loss:2.0235767140825676

epoch:[23/90],memory:[0.2693157196044922/10.91650390625], lr:[0.003]
train_accuracy:0.42565, train_loss:2.0342059679031372
val_acc:0.43250266524520253,val_loss:2.0226007580502965

epoch:[24/90],memory:[0.2693157196044922/10.91650390625], lr:[0.003]
train_accuracy:0.42565, train_loss:2.0342539389769234
val_acc:0.43250266524520253,val_loss:2.023747349217502

epoch:[25/90],memory:[0.2693157196044922/10.91650390625], lr:[0.003]
train_accuracy:0.42565, train_loss:2.0341327143828076
val_acc:0.43236940298507465,val_loss:2.024587107873929

epoch:[26/90],memory:[0.2693157196044922/10.91650390625], lr:[0.003]
train_accuracy:0.42565, train_loss:2.0341346023241678
val_acc:0.4324360341151386,val_loss:2.0227366825664985

epoch:[27/90],memory:[0.2693157196044922/10.91650390625], lr:[0.003]
train_accuracy:0.42565, train_loss:2.0340465596199038
val_acc:0.43250266524520253,val_loss:2.023517345314595

epoch:[28/90],memory:[0.2693157196044922/10.91650390625], lr:[0.003]
train_accuracy:0.42565, train_loss:2.0339651022752125
val_acc:0.4324360341151386,val_loss:2.0231598206420442

epoch:[29/90],memory:[0.2693157196044922/10.91650390625], lr:[0.003]
train_accuracy:0.42565, train_loss:2.0339948420683545
val_acc:0.4324360341151386,val_loss:2.0239716135362573

epoch:[30/90],memory:[0.2693157196044922/10.91650390625], lr:[0.00030000000000000003]
train_accuracy:0.42565, train_loss:2.0339561538060504
val_acc:0.43230277185501065,val_loss:2.0241291206528635

epoch:[31/90],memory:[0.2693157196044922/10.91650390625], lr:[0.00030000000000000003]
train_accuracy:0.42565, train_loss:2.0336533778031667
val_acc:0.4324360341151386,val_loss:2.0229879911266155

epoch:[32/90],memory:[0.2693157196044922/10.91650390625], lr:[0.00030000000000000003]
train_accuracy:0.42565, train_loss:2.033636020541191
val_acc:0.43236940298507465,val_loss:2.0228420940797722

epoch:[33/90],memory:[0.2693157196044922/10.91650390625], lr:[0.00030000000000000003]
train_accuracy:0.42565, train_loss:2.033642510509491
val_acc:0.43250266524520253,val_loss:2.022898373827497

epoch:[34/90],memory:[0.2693157196044922/10.91650390625], lr:[0.00030000000000000003]
train_accuracy:0.42565, train_loss:2.033648834315936
val_acc:0.43256929637526653,val_loss:2.0225345858378705

epoch:[35/90],memory:[0.2693157196044922/10.91650390625], lr:[0.00030000000000000003]
train_accuracy:0.42565, train_loss:2.0336325319449107
val_acc:0.4324360341151386,val_loss:2.0227889316930954

epoch:[36/90],memory:[0.2693157196044922/10.91650390625], lr:[0.00030000000000000003]
train_accuracy:0.42565, train_loss:2.0336410074710844
val_acc:0.43230277185501065,val_loss:2.023245046769124

epoch:[37/90],memory:[0.2693157196044922/10.91650390625], lr:[0.00030000000000000003]
train_accuracy:0.42565, train_loss:2.0336457885424295
val_acc:0.43230277185501065,val_loss:2.0228262145890357

epoch:[38/90],memory:[0.2693157196044922/10.91650390625], lr:[0.00030000000000000003]
train_accuracy:0.42565, train_loss:2.0336345805803933
val_acc:0.43236940298507465,val_loss:2.0229441634119194

epoch:[39/90],memory:[0.2693157196044922/10.91650390625], lr:[0.00030000000000000003]
train_accuracy:0.42565, train_loss:2.0336340746720634
val_acc:0.43256929637526653,val_loss:2.0227493500150344

epoch:[40/90],memory:[0.2693157196044922/10.91650390625], lr:[0.00030000000000000003]
train_accuracy:0.42565, train_loss:2.033644890658061
val_acc:0.43230277185501065,val_loss:2.023314224758636

epoch:[41/90],memory:[0.2693157196044922/10.91650390625], lr:[0.00030000000000000003]
train_accuracy:0.42565, train_loss:2.033635491927465
val_acc:0.4324360341151386,val_loss:2.0231178934131857

epoch:[42/90],memory:[0.2693157196044922/10.91650390625], lr:[0.00030000000000000003]
train_accuracy:0.42565, train_loss:2.0336348878383634
val_acc:0.43230277185501065,val_loss:2.022820825769957

epoch:[43/90],memory:[0.2693157196044922/10.91650390625], lr:[0.00030000000000000003]
train_accuracy:0.42565, train_loss:2.033645086256663
val_acc:0.43236940298507465,val_loss:2.023143057757095

epoch:[44/90],memory:[0.2693157196044922/10.91650390625], lr:[0.00030000000000000003]
train_accuracy:0.42565, train_loss:2.0336469692548116
val_acc:0.43236940298507465,val_loss:2.0229312528425187

epoch:[45/90],memory:[0.2693157196044922/10.91650390625], lr:[0.00030000000000000003]
train_accuracy:0.42565, train_loss:2.0336487732569375
val_acc:0.4326359275053305,val_loss:2.0223632302365577

epoch:[46/90],memory:[0.2693157196044922/10.91650390625], lr:[0.00030000000000000003]
train_accuracy:0.42565, train_loss:2.033635747051239
val_acc:0.43236940298507465,val_loss:2.0229667576391304

epoch:[47/90],memory:[0.2693157196044922/10.91650390625], lr:[0.00030000000000000003]
train_accuracy:0.42565, train_loss:2.0336475310166677
val_acc:0.4324360341151386,val_loss:2.0229915837997567

epoch:[48/90],memory:[0.2693157196044922/10.91650390625], lr:[0.00030000000000000003]
train_accuracy:0.42565, train_loss:2.033641709105174
val_acc:0.43250266524520253,val_loss:2.022769629192759

epoch:[49/90],memory:[0.2693157196044922/10.91650390625], lr:[0.00030000000000000003]
train_accuracy:0.42565, train_loss:2.033632613770167
val_acc:0.4324360341151386,val_loss:2.023038705020571

epoch:[50/90],memory:[0.2693157196044922/10.91650390625], lr:[0.00030000000000000003]
train_accuracy:0.42565, train_loss:2.0336477773745854
val_acc:0.43236940298507465,val_loss:2.02315333148818

epoch:[51/90],memory:[0.2693157196044922/10.91650390625], lr:[0.00030000000000000003]
train_accuracy:0.42565, train_loss:2.0336397363901138
val_acc:0.43256929637526653,val_loss:2.0227012892267595

epoch:[52/90],memory:[0.2693157196044922/10.91650390625], lr:[0.00030000000000000003]
train_accuracy:0.42565, train_loss:2.033643746582667
val_acc:0.4324360341151386,val_loss:2.0230317733435235

epoch:[53/90],memory:[0.2693157196044922/10.91650390625], lr:[0.00030000000000000003]
train_accuracy:0.42565, train_loss:2.0336282483259835
val_acc:0.4324360341151386,val_loss:2.023261020051391

epoch:[54/90],memory:[0.2693157196044922/10.91650390625], lr:[0.00030000000000000003]
train_accuracy:0.42565, train_loss:2.0336301789283753
val_acc:0.4326359275053305,val_loss:2.022422124582059

epoch:[55/90],memory:[0.2693157196044922/10.91650390625], lr:[0.00030000000000000003]
train_accuracy:0.42565, train_loss:2.033644800376892
val_acc:0.43250266524520253,val_loss:2.02281582279246

epoch:[56/90],memory:[0.2693157196044922/10.91650390625], lr:[0.00030000000000000003]
train_accuracy:0.42565, train_loss:2.0336360675652823
val_acc:0.4324360341151386,val_loss:2.023101501881695

epoch:[57/90],memory:[0.2693157196044922/10.91650390625], lr:[0.00030000000000000003]
train_accuracy:0.42565, train_loss:2.033648015546799
val_acc:0.4324360341151386,val_loss:2.02294789003665

epoch:[58/90],memory:[0.2693157196044922/10.91650390625], lr:[0.00030000000000000003]
train_accuracy:0.42565, train_loss:2.033642071310679
val_acc:0.4324360341151386,val_loss:2.022874430933995

epoch:[59/90],memory:[0.2693157196044922/10.91650390625], lr:[0.00030000000000000003]
train_accuracy:0.42565, train_loss:2.0336393560727437
val_acc:0.43236940298507465,val_loss:2.023150028958758

epoch:[60/90],memory:[0.2693157196044922/10.91650390625], lr:[3.0000000000000004e-05]
train_accuracy:0.42565, train_loss:2.0336351124922434
val_acc:0.43256929637526653,val_loss:2.0227416728351164

one of the best validation acc found
epoch:[61/90],memory:[0.2693157196044922/10.91650390625], lr:[3.0000000000000004e-05]
train_accuracy:0.42565, train_loss:2.033619999885559
val_acc:0.4327025586353945,val_loss:2.022429099215119

epoch:[62/90],memory:[0.2693157196044922/10.91650390625], lr:[3.0000000000000004e-05]
train_accuracy:0.42565, train_loss:2.0336130771160126
val_acc:0.4324360341151386,val_loss:2.0226820432173924

epoch:[63/90],memory:[0.2693157196044922/10.91650390625], lr:[3.0000000000000004e-05]
train_accuracy:0.42565, train_loss:2.0336103656133018
val_acc:0.43256929637526653,val_loss:2.0224817854000814

epoch:[64/90],memory:[0.2693157196044922/10.91650390625], lr:[3.0000000000000004e-05]
train_accuracy:0.42565, train_loss:2.033609730752309
val_acc:0.43250266524520253,val_loss:2.0226477565033347

epoch:[65/90],memory:[0.2693157196044922/10.91650390625], lr:[3.0000000000000004e-05]
train_accuracy:0.42565, train_loss:2.0336093106746675
val_acc:0.43256929637526653,val_loss:2.0225926603335562

epoch:[66/90],memory:[0.2693157196044922/10.91650390625], lr:[3.0000000000000004e-05]
train_accuracy:0.42565, train_loss:2.033608924372991
val_acc:0.43250266524520253,val_loss:2.0228760900782117

epoch:[67/90],memory:[0.2693157196044922/10.91650390625], lr:[3.0000000000000004e-05]
train_accuracy:0.42565, train_loss:2.0336090727329252
val_acc:0.4324360341151386,val_loss:2.0228575795952444

epoch:[68/90],memory:[0.2693157196044922/10.91650390625], lr:[3.0000000000000004e-05]
train_accuracy:0.42565, train_loss:2.033608847030004
val_acc:0.4324360341151386,val_loss:2.023069076954937

epoch:[69/90],memory:[0.2693157196044922/10.91650390625], lr:[3.0000000000000004e-05]
train_accuracy:0.42565, train_loss:2.0336086963653566
val_acc:0.43230277185501065,val_loss:2.0235447530299107

epoch:[70/90],memory:[0.2693157196044922/10.91650390625], lr:[3.0000000000000004e-05]
train_accuracy:0.42565, train_loss:2.0336088454564414
val_acc:0.43250266524520253,val_loss:2.022961754661633

epoch:[71/90],memory:[0.2693157196044922/10.91650390625], lr:[3.0000000000000004e-05]
train_accuracy:0.42565, train_loss:2.033608838971456
val_acc:0.43256929637526653,val_loss:2.0224784574529

epoch:[72/90],memory:[0.2693157196044922/10.91650390625], lr:[3.0000000000000004e-05]
train_accuracy:0.42565, train_loss:2.0336089263439177
val_acc:0.4326359275053305,val_loss:2.022482139469464

epoch:[73/90],memory:[0.2693157196044922/10.91650390625], lr:[3.0000000000000004e-05]
train_accuracy:0.42565, train_loss:2.033609046729406
val_acc:0.43250266524520253,val_loss:2.0227832204497447

epoch:[74/90],memory:[0.2693157196044922/10.91650390625], lr:[3.0000000000000004e-05]
train_accuracy:0.42565, train_loss:2.0336086553732553
val_acc:0.43236940298507465,val_loss:2.022921881441877

epoch:[75/90],memory:[0.2693157196044922/10.91650390625], lr:[3.0000000000000004e-05]
train_accuracy:0.42565, train_loss:2.0336086962540945
val_acc:0.43250266524520253,val_loss:2.0227598410679586

epoch:[76/90],memory:[0.2693157196044922/10.91650390625], lr:[3.0000000000000004e-05]
train_accuracy:0.42565, train_loss:2.033609319972992
val_acc:0.4324360341151386,val_loss:2.022917784353309

epoch:[77/90],memory:[0.2693157196044922/10.91650390625], lr:[3.0000000000000004e-05]
train_accuracy:0.42565, train_loss:2.0336088369528453
val_acc:0.43250266524520253,val_loss:2.0228672047922096

epoch:[78/90],memory:[0.2693157196044922/10.91650390625], lr:[3.0000000000000004e-05]
train_accuracy:0.42565, train_loss:2.0336087285995483
val_acc:0.43230277185501065,val_loss:2.0231264616126445

epoch:[79/90],memory:[0.2693157196044922/10.91650390625], lr:[3.0000000000000004e-05]
train_accuracy:0.42565, train_loss:2.0336086403687794
val_acc:0.43250266524520253,val_loss:2.0227849023428552

epoch:[80/90],memory:[0.2693157196044922/10.91650390625], lr:[3.0000000000000004e-05]
train_accuracy:0.42565, train_loss:2.033608799727758
val_acc:0.43230277185501065,val_loss:2.0228506718108905

epoch:[81/90],memory:[0.2693157196044922/10.91650390625], lr:[3.0000000000000004e-05]
train_accuracy:0.42565, train_loss:2.0336087640285494
val_acc:0.43256929637526653,val_loss:2.022473356489942

epoch:[82/90],memory:[0.2693157196044922/10.91650390625], lr:[3.0000000000000004e-05]
train_accuracy:0.42565, train_loss:2.0336088125387826
val_acc:0.43256929637526653,val_loss:2.0225551824834045

epoch:[83/90],memory:[0.2693157196044922/10.91650390625], lr:[3.0000000000000004e-05]
train_accuracy:0.42565, train_loss:2.033608971150716
val_acc:0.4324360341151386,val_loss:2.023034502956659

epoch:[84/90],memory:[0.2693157196044922/10.91650390625], lr:[3.0000000000000004e-05]
train_accuracy:0.42565, train_loss:2.0336086941878
val_acc:0.4326359275053305,val_loss:2.0224859931829897

epoch:[85/90],memory:[0.2693157196044922/10.91650390625], lr:[3.0000000000000004e-05]
train_accuracy:0.42565, train_loss:2.0336087189118066
val_acc:0.43250266524520253,val_loss:2.0225374425398006

epoch:[86/90],memory:[0.2693157196044922/10.91650390625], lr:[3.0000000000000004e-05]
train_accuracy:0.42565, train_loss:2.0336090507825215
val_acc:0.43236940298507465,val_loss:2.0230363015172834

epoch:[87/90],memory:[0.2693157196044922/10.91650390625], lr:[3.0000000000000004e-05]
train_accuracy:0.42565, train_loss:2.033608543348312
val_acc:0.43250266524520253,val_loss:2.0228413386639756

epoch:[88/90],memory:[0.2693157196044922/10.91650390625], lr:[3.0000000000000004e-05]
train_accuracy:0.42565, train_loss:2.0336085815111797
val_acc:0.4326359275053305,val_loss:2.0224599211709076

epoch:[89/90],memory:[0.2693157196044922/10.91650390625], lr:[3.0000000000000004e-05]
train_accuracy:0.42565, train_loss:2.0336088830629984
val_acc:0.43230277185501065,val_loss:2.0230319194956374

epoch:[90/90],memory:[0.2693157196044922/10.91650390625], lr:[3.0000000000000005e-06]
train_accuracy:0.42565, train_loss:2.0336088121732074
val_acc:0.4324360341151386,val_loss:2.0228548405775384

saved
model saved
correct are 51078/120000
Traceback (most recent call last):
  File "exlnet_15.py", line 337, in <module>
    lab_train,pre_train,predict_train,acc_train = model.evaluate(train_loader,name='train')
  File "exlnet_15.py", line 185, in evaluate
    self.fpr[name],self.tpr[name],_ = roc_curve(lab,pre[:,1])
  File "/DATA/kumar156/.local/lib/python3.7/site-packages/sklearn/utils/validation.py", line 63, in inner_f
    return f(*args, **kwargs)
  File "/DATA/kumar156/.local/lib/python3.7/site-packages/sklearn/metrics/_ranking.py", line 914, in roc_curve
    y_true, y_score, pos_label=pos_label, sample_weight=sample_weight)
  File "/DATA/kumar156/.local/lib/python3.7/site-packages/sklearn/metrics/_ranking.py", line 691, in _binary_clf_curve
    raise ValueError("{0} format is not supported".format(y_type))
ValueError: multiclass format is not supported
