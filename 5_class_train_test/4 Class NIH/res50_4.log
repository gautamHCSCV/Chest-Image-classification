cuda
52621
{'Atelectasis': 0, 'Cardiomegaly': 1, 'Consolidation': 2, 'Effusion': 3, 'No Finding': 4, 'Pneumothorax': 5}
32319
ResNet(
  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)
  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (relu): ReLU(inplace=True)
  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)
  (layer1): Sequential(
    (0): Bottleneck(
      (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (downsample): Sequential(
        (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (1): Bottleneck(
      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
    )
    (2): Bottleneck(
      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
    )
  )
  (layer2): Sequential(
    (0): Bottleneck(
      (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (downsample): Sequential(
        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)
        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (1): Bottleneck(
      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
    )
    (2): Bottleneck(
      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
    )
    (3): Bottleneck(
      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
    )
  )
  (layer3): Sequential(
    (0): Bottleneck(
      (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (downsample): Sequential(
        (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)
        (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (1): Bottleneck(
      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
    )
    (2): Bottleneck(
      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
    )
    (3): Bottleneck(
      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
    )
    (4): Bottleneck(
      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
    )
    (5): Bottleneck(
      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
    )
  )
  (layer4): Sequential(
    (0): Bottleneck(
      (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (downsample): Sequential(
        (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)
        (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (1): Bottleneck(
      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
    )
    (2): Bottleneck(
      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
    )
  )
  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))
  (fc): Sequential(
    (0): Dropout(p=0.4, inplace=False)
    (1): Linear(in_features=2048, out_features=4, bias=True)
  )
)
Epoch 0/29
-------------------------
Loss after 22368 examples: 1.326
Train Accuracy tensor(0.4144, dtype=torch.float64)
Validation Loss is 1.276704203605652
Validation Accuracy is 0.41250000000000003

One of the best validation accuracy found.

Epoch 1/29
-------------------------
Loss after 44752 examples: 1.352
Train Accuracy tensor(0.4118, dtype=torch.float64)
Validation Loss is 1.216532160758972
Validation Accuracy is 0.4285

One of the best validation accuracy found.

Epoch 2/29
-------------------------
Loss after 67136 examples: 1.453
Loss after 89536 examples: 1.222
Train Accuracy tensor(0.4265, dtype=torch.float64)
Validation Loss is 1.2915590925216676
Validation Accuracy is 0.41450000000000004

Epoch 3/29
-------------------------
Loss after 111920 examples: 1.282
Train Accuracy tensor(0.4401, dtype=torch.float64)
Validation Loss is 1.2194571609497071
Validation Accuracy is 0.436

One of the best validation accuracy found.

Epoch 4/29
-------------------------
Loss after 134304 examples: 1.400
Train Accuracy tensor(0.4407, dtype=torch.float64)
Validation Loss is 1.2155719509124756
Validation Accuracy is 0.4425

One of the best validation accuracy found.

Epoch 5/29
-------------------------
Loss after 156688 examples: 1.274
Loss after 179088 examples: 1.283
Train Accuracy tensor(0.4452, dtype=torch.float64)
Validation Loss is 1.1946199054718019
Validation Accuracy is 0.467

One of the best validation accuracy found.

Epoch 6/29
-------------------------
Loss after 201472 examples: 1.184
Train Accuracy tensor(0.4606, dtype=torch.float64)
Validation Loss is 1.201677978515625
Validation Accuracy is 0.4545

Epoch 7/29
-------------------------
Loss after 223856 examples: 1.306
Train Accuracy tensor(0.4590, dtype=torch.float64)
Validation Loss is 1.216866660118103
Validation Accuracy is 0.4585

Epoch 8/29
-------------------------
Loss after 246240 examples: 1.170
Loss after 268640 examples: 1.039
Train Accuracy tensor(0.4583, dtype=torch.float64)
Validation Loss is 1.181014105796814
Validation Accuracy is 0.46

Epoch 9/29
-------------------------
Loss after 291024 examples: 1.001
Train Accuracy tensor(0.4744, dtype=torch.float64)
Validation Loss is 1.321877643585205
Validation Accuracy is 0.4415

Epoch 10/29
-------------------------
Loss after 313408 examples: 1.180
Train Accuracy tensor(0.4844, dtype=torch.float64)
Validation Loss is 1.1405267000198365
Validation Accuracy is 0.4935

One of the best validation accuracy found.

Epoch 11/29
-------------------------
Loss after 335792 examples: 1.270
Loss after 358192 examples: 0.980
Train Accuracy tensor(0.4972, dtype=torch.float64)
Validation Loss is 1.1358914375305176
Validation Accuracy is 0.4975

One of the best validation accuracy found.

Epoch 12/29
-------------------------
Loss after 380576 examples: 1.010
Train Accuracy tensor(0.5089, dtype=torch.float64)
Validation Loss is 1.209150011062622
Validation Accuracy is 0.4825

Epoch 13/29
-------------------------
Loss after 402960 examples: 0.951
Train Accuracy tensor(0.5116, dtype=torch.float64)
Validation Loss is 1.0935010561943055
Validation Accuracy is 0.4905

Epoch 14/29
-------------------------
Loss after 425344 examples: 1.136
Loss after 447744 examples: 1.024
Train Accuracy tensor(0.5179, dtype=torch.float64)
Validation Loss is 1.1399927997589112
Validation Accuracy is 0.4905

Epoch 15/29
-------------------------
Loss after 470128 examples: 1.448
Train Accuracy tensor(0.5234, dtype=torch.float64)
Validation Loss is 1.0731785831451417
Validation Accuracy is 0.5125

One of the best validation accuracy found.

Epoch 16/29
-------------------------
Loss after 492512 examples: 1.060
Train Accuracy tensor(0.5291, dtype=torch.float64)
Validation Loss is 1.0940109815597534
Validation Accuracy is 0.4965

Epoch 17/29
-------------------------
Loss after 514896 examples: 1.128
Loss after 537296 examples: 1.313
Train Accuracy tensor(0.5311, dtype=torch.float64)
Validation Loss is 1.0800534982681274
Validation Accuracy is 0.5095000000000001

Epoch 18/29
-------------------------
Loss after 559680 examples: 1.204
Train Accuracy tensor(0.5352, dtype=torch.float64)
Validation Loss is 1.0817509880065919
Validation Accuracy is 0.5125

Epoch 19/29
-------------------------
Loss after 582064 examples: 0.978
Train Accuracy tensor(0.5420, dtype=torch.float64)
Validation Loss is 1.1224406595230103
Validation Accuracy is 0.513

One of the best validation accuracy found.

Epoch 20/29
-------------------------
Loss after 604448 examples: 1.025
Loss after 626848 examples: 0.963
Train Accuracy tensor(0.5451, dtype=torch.float64)
Validation Loss is 1.0835500183105469
Validation Accuracy is 0.53

One of the best validation accuracy found.

Epoch 21/29
-------------------------
Loss after 649232 examples: 1.021
Train Accuracy tensor(0.5515, dtype=torch.float64)
Validation Loss is 1.0797411212921142
Validation Accuracy is 0.5205

Epoch 22/29
-------------------------
Loss after 671616 examples: 1.016
Train Accuracy tensor(0.5519, dtype=torch.float64)
Validation Loss is 1.0921608276367187
Validation Accuracy is 0.504

Epoch 23/29
-------------------------
Loss after 694000 examples: 1.038
Loss after 716400 examples: 1.165
Train Accuracy tensor(0.5603, dtype=torch.float64)
Validation Loss is 1.120525230407715
Validation Accuracy is 0.497

Epoch 24/29
-------------------------
Loss after 738784 examples: 1.005
Train Accuracy tensor(0.5662, dtype=torch.float64)
Validation Loss is 1.1515053277015685
Validation Accuracy is 0.4805

Epoch 25/29
-------------------------
Loss after 761168 examples: 1.031
Train Accuracy tensor(0.5758, dtype=torch.float64)
Validation Loss is 1.1365200328826903
Validation Accuracy is 0.46900000000000003

Epoch 26/29
-------------------------
Loss after 783552 examples: 0.922
Loss after 805952 examples: 0.962
Train Accuracy tensor(0.5835, dtype=torch.float64)
Validation Loss is 1.160961404800415
Validation Accuracy is 0.4845

Epoch 27/29
-------------------------
Loss after 828336 examples: 0.824
Train Accuracy tensor(0.5951, dtype=torch.float64)
Validation Loss is 1.188581678390503
Validation Accuracy is 0.47400000000000003

Epoch 28/29
-------------------------
Loss after 850720 examples: 0.693
Train Accuracy tensor(0.6029, dtype=torch.float64)
Validation Loss is 1.215028037071228
Validation Accuracy is 0.467

Epoch 29/29
-------------------------
Loss after 873104 examples: 0.859
Loss after 895504 examples: 1.004
Train Accuracy tensor(0.6169, dtype=torch.float64)
Validation Loss is 1.3052140340805054
Validation Accuracy is 0.4425

Training complete in 113m 30s
Test Loss is 1.3532845902966109
Test Accuracy is 0.4106583072100313
