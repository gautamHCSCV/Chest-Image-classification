cuda
52621
{'Atelectasis': 0, 'Cardiomegaly': 1, 'Consolidation': 2, 'Effusion': 3, 'No Finding': 4, 'Pneumothorax': 5}
32319
ShuffleNetV2(
  (conv1): Sequential(
    (0): Conv2d(3, 24, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
    (1): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): ReLU(inplace=True)
  )
  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)
  (stage2): Sequential(
    (0): InvertedResidual(
      (branch1): Sequential(
        (0): Conv2d(24, 24, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=24, bias=False)
        (1): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (2): Conv2d(24, 58, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (3): BatchNorm2d(58, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (4): ReLU(inplace=True)
      )
      (branch2): Sequential(
        (0): Conv2d(24, 58, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (1): BatchNorm2d(58, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (2): ReLU(inplace=True)
        (3): Conv2d(58, 58, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=58, bias=False)
        (4): BatchNorm2d(58, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (5): Conv2d(58, 58, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (6): BatchNorm2d(58, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (7): ReLU(inplace=True)
      )
    )
    (1): InvertedResidual(
      (branch1): Sequential()
      (branch2): Sequential(
        (0): Conv2d(58, 58, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (1): BatchNorm2d(58, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (2): ReLU(inplace=True)
        (3): Conv2d(58, 58, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=58, bias=False)
        (4): BatchNorm2d(58, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (5): Conv2d(58, 58, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (6): BatchNorm2d(58, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (7): ReLU(inplace=True)
      )
    )
    (2): InvertedResidual(
      (branch1): Sequential()
      (branch2): Sequential(
        (0): Conv2d(58, 58, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (1): BatchNorm2d(58, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (2): ReLU(inplace=True)
        (3): Conv2d(58, 58, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=58, bias=False)
        (4): BatchNorm2d(58, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (5): Conv2d(58, 58, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (6): BatchNorm2d(58, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (7): ReLU(inplace=True)
      )
    )
    (3): InvertedResidual(
      (branch1): Sequential()
      (branch2): Sequential(
        (0): Conv2d(58, 58, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (1): BatchNorm2d(58, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (2): ReLU(inplace=True)
        (3): Conv2d(58, 58, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=58, bias=False)
        (4): BatchNorm2d(58, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (5): Conv2d(58, 58, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (6): BatchNorm2d(58, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (7): ReLU(inplace=True)
      )
    )
  )
  (stage3): Sequential(
    (0): InvertedResidual(
      (branch1): Sequential(
        (0): Conv2d(116, 116, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=116, bias=False)
        (1): BatchNorm2d(116, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (2): Conv2d(116, 116, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (3): BatchNorm2d(116, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (4): ReLU(inplace=True)
      )
      (branch2): Sequential(
        (0): Conv2d(116, 116, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (1): BatchNorm2d(116, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (2): ReLU(inplace=True)
        (3): Conv2d(116, 116, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=116, bias=False)
        (4): BatchNorm2d(116, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (5): Conv2d(116, 116, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (6): BatchNorm2d(116, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (7): ReLU(inplace=True)
      )
    )
    (1): InvertedResidual(
      (branch1): Sequential()
      (branch2): Sequential(
        (0): Conv2d(116, 116, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (1): BatchNorm2d(116, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (2): ReLU(inplace=True)
        (3): Conv2d(116, 116, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=116, bias=False)
        (4): BatchNorm2d(116, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (5): Conv2d(116, 116, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (6): BatchNorm2d(116, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (7): ReLU(inplace=True)
      )
    )
    (2): InvertedResidual(
      (branch1): Sequential()
      (branch2): Sequential(
        (0): Conv2d(116, 116, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (1): BatchNorm2d(116, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (2): ReLU(inplace=True)
        (3): Conv2d(116, 116, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=116, bias=False)
        (4): BatchNorm2d(116, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (5): Conv2d(116, 116, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (6): BatchNorm2d(116, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (7): ReLU(inplace=True)
      )
    )
    (3): InvertedResidual(
      (branch1): Sequential()
      (branch2): Sequential(
        (0): Conv2d(116, 116, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (1): BatchNorm2d(116, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (2): ReLU(inplace=True)
        (3): Conv2d(116, 116, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=116, bias=False)
        (4): BatchNorm2d(116, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (5): Conv2d(116, 116, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (6): BatchNorm2d(116, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (7): ReLU(inplace=True)
      )
    )
    (4): InvertedResidual(
      (branch1): Sequential()
      (branch2): Sequential(
        (0): Conv2d(116, 116, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (1): BatchNorm2d(116, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (2): ReLU(inplace=True)
        (3): Conv2d(116, 116, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=116, bias=False)
        (4): BatchNorm2d(116, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (5): Conv2d(116, 116, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (6): BatchNorm2d(116, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (7): ReLU(inplace=True)
      )
    )
    (5): InvertedResidual(
      (branch1): Sequential()
      (branch2): Sequential(
        (0): Conv2d(116, 116, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (1): BatchNorm2d(116, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (2): ReLU(inplace=True)
        (3): Conv2d(116, 116, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=116, bias=False)
        (4): BatchNorm2d(116, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (5): Conv2d(116, 116, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (6): BatchNorm2d(116, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (7): ReLU(inplace=True)
      )
    )
    (6): InvertedResidual(
      (branch1): Sequential()
      (branch2): Sequential(
        (0): Conv2d(116, 116, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (1): BatchNorm2d(116, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (2): ReLU(inplace=True)
        (3): Conv2d(116, 116, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=116, bias=False)
        (4): BatchNorm2d(116, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (5): Conv2d(116, 116, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (6): BatchNorm2d(116, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (7): ReLU(inplace=True)
      )
    )
    (7): InvertedResidual(
      (branch1): Sequential()
      (branch2): Sequential(
        (0): Conv2d(116, 116, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (1): BatchNorm2d(116, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (2): ReLU(inplace=True)
        (3): Conv2d(116, 116, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=116, bias=False)
        (4): BatchNorm2d(116, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (5): Conv2d(116, 116, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (6): BatchNorm2d(116, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (7): ReLU(inplace=True)
      )
    )
  )
  (stage4): Sequential(
    (0): InvertedResidual(
      (branch1): Sequential(
        (0): Conv2d(232, 232, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=232, bias=False)
        (1): BatchNorm2d(232, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (2): Conv2d(232, 232, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (3): BatchNorm2d(232, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (4): ReLU(inplace=True)
      )
      (branch2): Sequential(
        (0): Conv2d(232, 232, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (1): BatchNorm2d(232, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (2): ReLU(inplace=True)
        (3): Conv2d(232, 232, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=232, bias=False)
        (4): BatchNorm2d(232, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (5): Conv2d(232, 232, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (6): BatchNorm2d(232, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (7): ReLU(inplace=True)
      )
    )
    (1): InvertedResidual(
      (branch1): Sequential()
      (branch2): Sequential(
        (0): Conv2d(232, 232, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (1): BatchNorm2d(232, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (2): ReLU(inplace=True)
        (3): Conv2d(232, 232, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=232, bias=False)
        (4): BatchNorm2d(232, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (5): Conv2d(232, 232, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (6): BatchNorm2d(232, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (7): ReLU(inplace=True)
      )
    )
    (2): InvertedResidual(
      (branch1): Sequential()
      (branch2): Sequential(
        (0): Conv2d(232, 232, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (1): BatchNorm2d(232, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (2): ReLU(inplace=True)
        (3): Conv2d(232, 232, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=232, bias=False)
        (4): BatchNorm2d(232, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (5): Conv2d(232, 232, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (6): BatchNorm2d(232, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (7): ReLU(inplace=True)
      )
    )
    (3): InvertedResidual(
      (branch1): Sequential()
      (branch2): Sequential(
        (0): Conv2d(232, 232, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (1): BatchNorm2d(232, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (2): ReLU(inplace=True)
        (3): Conv2d(232, 232, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=232, bias=False)
        (4): BatchNorm2d(232, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (5): Conv2d(232, 232, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (6): BatchNorm2d(232, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (7): ReLU(inplace=True)
      )
    )
  )
  (conv5): Sequential(
    (0): Conv2d(464, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
    (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): ReLU(inplace=True)
  )
  (fc): Linear(in_features=1024, out_features=4, bias=True)
)
Epoch 0/29
-------------------------
Loss after 22368 examples: 1.339
Train Accuracy tensor(0.5182, dtype=torch.float64)
Validation Loss is 1.0469582691192627
Validation Accuracy is 0.5455

One of the best validation accuracy found.

Epoch 1/29
-------------------------
Loss after 44752 examples: 1.079
Train Accuracy tensor(0.5492, dtype=torch.float64)
Validation Loss is 1.0461742715835571
Validation Accuracy is 0.55

One of the best validation accuracy found.

Epoch 2/29
-------------------------
Loss after 67136 examples: 0.858
Loss after 89536 examples: 1.002
Train Accuracy tensor(0.5568, dtype=torch.float64)
Validation Loss is 1.029310908317566
Validation Accuracy is 0.545

Epoch 3/29
-------------------------
Loss after 111920 examples: 1.188
Train Accuracy tensor(0.5661, dtype=torch.float64)
Validation Loss is 1.0612613868713379
Validation Accuracy is 0.5445

Epoch 4/29
-------------------------
Loss after 134304 examples: 0.951
Train Accuracy tensor(0.5770, dtype=torch.float64)
Validation Loss is 1.0169199256896972
Validation Accuracy is 0.562

One of the best validation accuracy found.

Epoch 5/29
-------------------------
Loss after 156688 examples: 1.077
Loss after 179088 examples: 1.212
Train Accuracy tensor(0.5823, dtype=torch.float64)
Validation Loss is 1.0197658548355102
Validation Accuracy is 0.548

Epoch 6/29
-------------------------
Loss after 201472 examples: 0.819
Train Accuracy tensor(0.5899, dtype=torch.float64)
Validation Loss is 1.031239172935486
Validation Accuracy is 0.5505

Epoch 7/29
-------------------------
Loss after 223856 examples: 1.103
Train Accuracy tensor(0.5998, dtype=torch.float64)
Validation Loss is 1.0602060613632203
Validation Accuracy is 0.5515

Epoch 8/29
-------------------------
Loss after 246240 examples: 1.237
Loss after 268640 examples: 0.902
Train Accuracy tensor(0.6102, dtype=torch.float64)
Validation Loss is 1.0748335494995118
Validation Accuracy is 0.534

Epoch 9/29
-------------------------
Loss after 291024 examples: 0.975
Train Accuracy tensor(0.6167, dtype=torch.float64)
Validation Loss is 1.0957174367904663
Validation Accuracy is 0.5245

Epoch 10/29
-------------------------
Loss after 313408 examples: 1.016
Train Accuracy tensor(0.6283, dtype=torch.float64)
Validation Loss is 1.1404762659072876
Validation Accuracy is 0.5215

Epoch 11/29
-------------------------
Loss after 335792 examples: 0.897
Loss after 358192 examples: 1.025
Train Accuracy tensor(0.6413, dtype=torch.float64)
Validation Loss is 1.1685953607559205
Validation Accuracy is 0.4915

Epoch 12/29
-------------------------
Loss after 380576 examples: 0.755
Train Accuracy tensor(0.6480, dtype=torch.float64)
Validation Loss is 1.2378530812263489
Validation Accuracy is 0.493

Epoch 13/29
-------------------------
Loss after 402960 examples: 0.793
Train Accuracy tensor(0.6601, dtype=torch.float64)
Validation Loss is 1.2808258562088013
Validation Accuracy is 0.47950000000000004

Epoch 14/29
-------------------------
Loss after 425344 examples: 0.774
Loss after 447744 examples: 0.720
Train Accuracy tensor(0.6664, dtype=torch.float64)
Validation Loss is 1.3159444932937623
Validation Accuracy is 0.4605

Epoch 15/29
-------------------------
Loss after 470128 examples: 0.691
Train Accuracy tensor(0.6783, dtype=torch.float64)
Validation Loss is 1.3304212446212769
Validation Accuracy is 0.488

Epoch 16/29
-------------------------
Loss after 492512 examples: 0.628
Train Accuracy tensor(0.6827, dtype=torch.float64)
Validation Loss is 1.3801879987716674
Validation Accuracy is 0.46900000000000003

Epoch 17/29
-------------------------
Loss after 514896 examples: 0.585
Loss after 537296 examples: 0.717
Train Accuracy tensor(0.6907, dtype=torch.float64)
Validation Loss is 1.4575032396316527
Validation Accuracy is 0.439

Epoch 18/29
-------------------------
Loss after 559680 examples: 0.584
Train Accuracy tensor(0.6979, dtype=torch.float64)
Validation Loss is 1.4517143039703369
Validation Accuracy is 0.4595

Epoch 19/29
-------------------------
Loss after 582064 examples: 0.514
Train Accuracy tensor(0.7021, dtype=torch.float64)
Validation Loss is 1.46753719997406
Validation Accuracy is 0.47200000000000003

Epoch 20/29
-------------------------
Loss after 604448 examples: 0.463
Loss after 626848 examples: 0.551
Train Accuracy tensor(0.7047, dtype=torch.float64)
Validation Loss is 1.5388697443008423
Validation Accuracy is 0.4325

Epoch 21/29
-------------------------
Loss after 649232 examples: 0.627
Train Accuracy tensor(0.7113, dtype=torch.float64)
Validation Loss is 1.6633399238586426
Validation Accuracy is 0.4475

Epoch 22/29
-------------------------
Loss after 671616 examples: 0.626
Train Accuracy tensor(0.7129, dtype=torch.float64)
Validation Loss is 1.6151013021469116
Validation Accuracy is 0.4305

Epoch 23/29
-------------------------
Loss after 694000 examples: 0.454
Loss after 716400 examples: 0.542
Train Accuracy tensor(0.7182, dtype=torch.float64)
Validation Loss is 1.6470660190582276
Validation Accuracy is 0.4245

Epoch 24/29
-------------------------
Loss after 738784 examples: 0.758
Train Accuracy tensor(0.7228, dtype=torch.float64)
Validation Loss is 1.7476122102737426
Validation Accuracy is 0.41050000000000003

Epoch 25/29
-------------------------
Loss after 761168 examples: 0.675
Train Accuracy tensor(0.7238, dtype=torch.float64)
Validation Loss is 1.6886669273376465
Validation Accuracy is 0.425

Epoch 26/29
-------------------------
Loss after 783552 examples: 0.489
Loss after 805952 examples: 0.657
Train Accuracy tensor(0.7272, dtype=torch.float64)
Validation Loss is 1.8049776916503906
Validation Accuracy is 0.432

Epoch 27/29
-------------------------
Loss after 828336 examples: 0.698
Train Accuracy tensor(0.7318, dtype=torch.float64)
Validation Loss is 1.916916136741638
Validation Accuracy is 0.4175

Epoch 28/29
-------------------------
Loss after 850720 examples: 0.397
Train Accuracy tensor(0.7353, dtype=torch.float64)
Validation Loss is 1.9450875205993652
Validation Accuracy is 0.41400000000000003

Epoch 29/29
-------------------------
Loss after 873104 examples: 0.445
Loss after 895504 examples: 0.440
Train Accuracy tensor(0.7350, dtype=torch.float64)
Validation Loss is 2.0092340717315675
Validation Accuracy is 0.3985

Training complete in 41m 9s
Test Loss is 2.233515827259674
Test Accuracy is 0.42006269592476486
