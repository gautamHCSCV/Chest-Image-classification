{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "98f4fc97",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import time\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pydicom\n",
    "import pickle\n",
    "from PIL import Image\n",
    "from sklearn.model_selection import train_test_split\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fd50b1eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "import torch.nn.functional as F\n",
    "from torchvision import transforms\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torchvision.models as models\n",
    "from sklearn.metrics import precision_recall_fscore_support, roc_auc_score\n",
    "import matplotlib.pyplot as plt\n",
    "import sklearn.metrics as metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1b980df2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:5\n"
     ]
    }
   ],
   "source": [
    "class Config():\n",
    "    base_path = \"../../../dataset/pediatric_dataset/physionet.org/files/vindr-pcxr/1.0.0/\"\n",
    "    train_path = base_path + \"train/\"\n",
    "    test_path = base_path + \"test/\"\n",
    "    train_csv_path = base_path + \"annotations_train.csv\"\n",
    "    test_csv_path = base_path + \"annotations_test.csv\"\n",
    "    image_size = (224,224)\n",
    "    BATCH_SIZE = 32\n",
    "    pin_memory = True\n",
    "    num_workers = 3\n",
    "    lr=0.001\n",
    "    EPOCHS=30\n",
    "    gpu_id=5\n",
    "    device = torch.device(f'cuda:{gpu_id}' if torch.cuda.is_available() else 'cpu')\n",
    "    val_split = 0.1\n",
    "    SEED=42\n",
    "    return_logs=False\n",
    "    load = False\n",
    "    model_name = \"shufflenet\"\n",
    "    roc_title = f'roc_{model_name}'\n",
    "    checkpoint = f\"../saved_models/{model_name}_checkpoint.pt\"\n",
    "    saved_path = f'../saved_models/{model_name}_v1.pt'\n",
    "    loss_acc_path = f'../loss_acc_roc/loss-acc-{model_name}.svg'\n",
    "    roc_path = f'../loss_acc_roc/roc-{model_name}.svg'\n",
    "    fta_path = f'../roc_pickle_files/fta_{model_name}.pkl'\n",
    "\n",
    "config = Config()\n",
    "\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\"  \n",
    "print(config.device)\n",
    "\n",
    "random.seed(config.SEED)\n",
    "np.random.seed(config.SEED)\n",
    "torch.manual_seed(config.SEED)\n",
    "torch.cuda.manual_seed(config.SEED)\n",
    "torch.backends.cudnn.benchmarks = True\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cuda.matmul.allow_tf32 = True\n",
    "torch.backends.cudnn.allow_tf32 = True\n",
    "\n",
    "\n",
    "class PCXRDataset():\n",
    "    def __init__(self,csv_file,dir_path):\n",
    "        self.dir_path = dir_path\n",
    "        csv_ = pd.read_csv(csv_file)\n",
    "\n",
    "        csv_ = csv_.drop_duplicates(subset=['image_id'])\n",
    "        csv_.class_name = csv_.class_name.apply(lambda x:0 if x=='No finding' else 1)\n",
    "        csv_ = np.array(csv_.loc[:,['image_id','class_name']])\n",
    "        self.images = csv_\n",
    "\n",
    "        self.transformations = torchvision.transforms.Compose([\n",
    "            torchvision.transforms.Resize(config.image_size),\n",
    "            torchvision.transforms.ToTensor()\n",
    "        ])\n",
    "            \n",
    "    def __len__(self):\n",
    "        return len(self.images)\n",
    "\n",
    "    def __getitem__(self,idx):\n",
    "        img_id, label = self.images[idx]\n",
    "        img_path = os.path.join(self.dir_path,f'{img_id}.dicom')\n",
    "        ds = pydicom.dcmread(img_path)\n",
    "        new_img = ds.pixel_array.astype('float')\n",
    "        new_img = np.maximum(new_img,0) / new_img.max()\n",
    "        new_img = (new_img * 255).astype(np.uint8)\n",
    "        final_img = Image.fromarray(new_img)\n",
    "        final_img = final_img.convert('RGB')\n",
    "        final_img = self.transformations(final_img)\n",
    "        return final_img, label\n",
    "\n",
    "def GetDataloader():\n",
    "    train_data = PCXRDataset(config.train_csv_path,config.train_path)\n",
    "    test_data = PCXRDataset(config.test_csv_path,config.test_path)\n",
    "    total_len = len(train_data)\n",
    "    val_len = int(config.val_split * total_len)\n",
    "    train_len = total_len - val_len\n",
    "    training_data,val_data = torch.utils.data.dataset.random_split(train_data,[train_len,val_len])\n",
    "\n",
    "    train_loader = torch.utils.data.DataLoader(\n",
    "        training_data,\n",
    "        shuffle=True,\n",
    "        batch_size=config.BATCH_SIZE,\n",
    "        pin_memory = config.pin_memory,\n",
    "        num_workers = config.num_workers\n",
    "        )\n",
    "    \n",
    "    val_loader = torch.utils.data.DataLoader(\n",
    "        val_data,\n",
    "        shuffle=True,\n",
    "        batch_size=config.BATCH_SIZE,\n",
    "        pin_memory = config.pin_memory,\n",
    "        num_workers = config.num_workers\n",
    "        )\n",
    "\n",
    "    test_loader = torch.utils.data.DataLoader(\n",
    "        test_data,\n",
    "        shuffle=True,\n",
    "        batch_size=config.BATCH_SIZE,\n",
    "        pin_memory = config.pin_memory,\n",
    "        num_workers = config.num_workers\n",
    "        )\n",
    "\n",
    "    return train_loader, test_loader, val_loader, training_data, test_data, val_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d2c0339a",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dl,test_dl,valid_dl, train_data,test_data, valid_data = GetDataloader()\n",
    "criterion = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a2069400",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluation(model,test_dl):\n",
    "    model.eval()\n",
    "    running_loss = 0.0\n",
    "    running_corrects = 0\n",
    "    total = 0\n",
    "    preds = []\n",
    "    pred_labels = []\n",
    "    labels = []\n",
    "\n",
    "            # Disable gradient calculation for validation or inference using torch.no_rad()\n",
    "    with torch.no_grad():\n",
    "                for x,y in test_dl:\n",
    "                    x = x.to(config.device)\n",
    "                    y = y.to(config.device) #CHW --> #HWC\n",
    "                    valid_logits = model(x)\n",
    "                    predict_prob = F.softmax(valid_logits)\n",
    "                    _,predictions = predict_prob.max(1)\n",
    "                    predictions = predictions.to('cpu')\n",
    "\n",
    "                    _, valid_preds = torch.max(valid_logits, 1)\n",
    "                    valid_loss = criterion(valid_logits,y)\n",
    "                    running_loss += valid_loss.item() * x.size(0)\n",
    "                    running_corrects += torch.sum(valid_preds == y.data)\n",
    "                    total += y.size(0)\n",
    "                    predict_prob = predict_prob.to('cpu')\n",
    "\n",
    "                    pred_labels.extend(list(predictions.numpy()))\n",
    "                    preds.extend(list(predict_prob.numpy()))\n",
    "                    y = y.to('cpu')\n",
    "                    labels.extend(list(y.numpy()))\n",
    "\n",
    "    epoch_loss = running_loss / len(test_data)\n",
    "    epoch_acc = running_corrects.double() / len(test_data)\n",
    "    print(\"Test Loss is {}\".format(epoch_loss))\n",
    "    print(\"Test Accuracy is {}\".format(epoch_acc.cpu()))\n",
    "    return np.array(labels),np.array(pred_labels),np.array(preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4d591afc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss is 0.6257334280500433\n",
      "Test Accuracy is 0.6943450250536864\n"
     ]
    }
   ],
   "source": [
    "efficientnet = models.efficientnet_b4(pretrained = True)\n",
    "efficientnet.classifier[1] = nn.Linear(in_features = 1792, out_features = 2, bias = True)\n",
    "model = efficientnet\n",
    "model.load_state_dict(torch.load('Child/efficientnet_best.pt'))\n",
    "model = model.to(config.device)\n",
    "labels, pred_labels, preds = evaluation(model,test_dl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e086cc9d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "    abnormal       0.70      0.93      0.80       907\n",
      "      normal       0.67      0.25      0.37       490\n",
      "\n",
      "    accuracy                           0.69      1397\n",
      "   macro avg       0.68      0.59      0.58      1397\n",
      "weighted avg       0.69      0.69      0.65      1397\n",
      "\n",
      "\n",
      " classwise accuracy\n",
      "[0.93384785 0.25102041]\n",
      "0.6828724433544091\n"
     ]
    }
   ],
   "source": [
    "print(metrics.classification_report(labels,pred_labels,target_names = ['abnormal','normal']))\n",
    "cm = metrics.confusion_matrix(labels,pred_labels)\n",
    "print('\\n classwise accuracy')\n",
    "cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "print(cm.diagonal())\n",
    "\n",
    "print(roc_auc_score(1-np.array(labels), np.array(preds)[:,0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a9fc08fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "fpr_tpr_auc = {}\n",
    "fpr,tpr,_ = metrics.roc_curve(labels,preds[:,1])\n",
    "aucc = metrics.auc(fpr,tpr)\n",
    "fpr_tpr_auc[1] = [fpr,tpr,aucc]\n",
    "model.train()\n",
    "with open('eff_b4.pkl','wb') as f:\n",
    "    pickle.dump(fpr_tpr_auc,f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "183aa9d6",
   "metadata": {},
   "source": [
    "# ShuffleNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "8aac283f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss is 1.2722560653707002\n",
      "Test Accuracy is 0.6993557623478883\n"
     ]
    }
   ],
   "source": [
    "shufflenet = models.shufflenet_v2_x1_0(pretrained = True)\n",
    "shufflenet.fc = nn.Linear(in_features = 1024, out_features = 2, bias=True)\n",
    "model = shufflenet\n",
    "model.load_state_dict(torch.load('Child/shufflenet_best.pt'))\n",
    "model = model.to(config.device)\n",
    "labels, pred_labels, preds = evaluation(model,test_dl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "8401c1cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "    abnormal       0.73      0.85      0.79       907\n",
      "      normal       0.60      0.43      0.50       490\n",
      "\n",
      "    accuracy                           0.70      1397\n",
      "   macro avg       0.67      0.64      0.64      1397\n",
      "weighted avg       0.69      0.70      0.68      1397\n",
      "\n",
      "\n",
      " classwise accuracy\n",
      "[0.84674752 0.42653061]\n",
      "0.6976182975946719\n"
     ]
    }
   ],
   "source": [
    "print(metrics.classification_report(labels,pred_labels,target_names = ['abnormal','normal']))\n",
    "cm = metrics.confusion_matrix(labels,pred_labels)\n",
    "print('\\n classwise accuracy')\n",
    "cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "print(cm.diagonal())\n",
    "\n",
    "print(roc_auc_score(1-np.array(labels), np.array(preds)[:,0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "14f568f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "fpr_tpr_auc = {}\n",
    "fpr,tpr,_ = metrics.roc_curve(labels,preds[:,1])\n",
    "aucc = metrics.auc(fpr,tpr)\n",
    "fpr_tpr_auc[1] = [fpr,tpr,aucc]\n",
    "model.train()\n",
    "with open('shuffle.pkl','wb') as f:\n",
    "    pickle.dump(fpr_tpr_auc,f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bd8826c",
   "metadata": {},
   "source": [
    "# ResNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "ee730537",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss is 0.5901733895199761\n",
      "Test Accuracy is 0.6986399427344309\n"
     ]
    }
   ],
   "source": [
    "resnet50 = torchvision.models.resnet50(pretrained=True)\n",
    "resnet50.fc = nn.Sequential(\n",
    "    nn.Dropout(0.4),\n",
    "    nn.Linear(in_features = 2048, out_features = 2, bias = True))\n",
    "model = resnet50\n",
    "model.load_state_dict(torch.load('Child/resnet_best.pt'))\n",
    "model = model.to(config.device)\n",
    "labels, pred_labels, preds = evaluation(model,test_dl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "2097b916",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "    abnormal       0.72      0.88      0.79       907\n",
      "      normal       0.62      0.37      0.46       490\n",
      "\n",
      "    accuracy                           0.70      1397\n",
      "   macro avg       0.67      0.62      0.63      1397\n",
      "weighted avg       0.68      0.70      0.68      1397\n",
      "\n",
      "\n",
      " classwise accuracy\n",
      "[0.87541345 0.37142857]\n",
      "0.6998312445154468\n"
     ]
    }
   ],
   "source": [
    "print(metrics.classification_report(labels,pred_labels,target_names = ['abnormal','normal']))\n",
    "cm = metrics.confusion_matrix(labels,pred_labels)\n",
    "print('\\n classwise accuracy')\n",
    "cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "print(cm.diagonal())\n",
    "\n",
    "print(roc_auc_score(1-np.array(labels), np.array(preds)[:,0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "52a3385a",
   "metadata": {},
   "outputs": [],
   "source": [
    "fpr_tpr_auc = {}\n",
    "fpr,tpr,_ = metrics.roc_curve(labels,preds[:,1])\n",
    "aucc = metrics.auc(fpr,tpr)\n",
    "fpr_tpr_auc[1] = [fpr,tpr,aucc]\n",
    "model.train()\n",
    "with open('resnet.pkl','wb') as f:\n",
    "    pickle.dump(fpr_tpr_auc,f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78d618e2",
   "metadata": {},
   "source": [
    "# Squeezenet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "3a7ad89c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss is 0.6931474786958441\n",
      "Test Accuracy is 0.6492483894058697\n"
     ]
    }
   ],
   "source": [
    "squeezenet = torchvision.models.squeezenet1_0(pretrained=True)\n",
    "squeezenet.classifier[1] = nn.Conv2d(512, 2, kernel_size=(1, 1), stride=(1, 1))\n",
    "model = squeezenet\n",
    "model.load_state_dict(torch.load('Child/squeezenet_best.pt'))\n",
    "model = model.to(config.device)\n",
    "labels, pred_labels, preds = evaluation(model,test_dl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "065fa809",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "    abnormal       0.65      1.00      0.79       907\n",
      "      normal       0.00      0.00      0.00       490\n",
      "\n",
      "    accuracy                           0.65      1397\n",
      "   macro avg       0.32      0.50      0.39      1397\n",
      "weighted avg       0.42      0.65      0.51      1397\n",
      "\n",
      "\n",
      " classwise accuracy\n",
      "[1. 0.]\n",
      "0.5\n"
     ]
    }
   ],
   "source": [
    "print(metrics.classification_report(labels,pred_labels,target_names = ['abnormal','normal']))\n",
    "cm = metrics.confusion_matrix(labels,pred_labels)\n",
    "print('\\n classwise accuracy')\n",
    "cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "print(cm.diagonal())\n",
    "\n",
    "print(roc_auc_score(1-np.array(labels), np.array(preds)[:,0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "27137817",
   "metadata": {},
   "outputs": [],
   "source": [
    "fpr_tpr_auc = {}\n",
    "fpr,tpr,_ = metrics.roc_curve(labels,preds[:,1])\n",
    "aucc = metrics.auc(fpr,tpr)\n",
    "fpr_tpr_auc[1] = [fpr,tpr,aucc]\n",
    "model.train()\n",
    "with open('squeeze.pkl','wb') as f:\n",
    "    pickle.dump(fpr_tpr_auc,f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2f1b089",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
